{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporrint necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow_text\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_description</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2212</td>\n",
       "      <td>17908351952371091</td>\n",
       "      <td>لخسارة الوزن الزائد والكرش بمدة قياسية مع عدم ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2217</td>\n",
       "      <td>17935944230085744</td>\n",
       "      <td>🔥🔥🔥</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2215S</td>\n",
       "      <td>17899518356507020</td>\n",
       "      <td>This is so good😍 would be great it If you add ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2214</td>\n",
       "      <td>18014766136389857</td>\n",
       "      <td>😍</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2203</td>\n",
       "      <td>17924318627206870</td>\n",
       "      <td>طبق رائع ومميز تبارك الرحمن تسلم ايدك يارب 😍</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  campaign_id         comment_id  \\\n",
       "0        2212  17908351952371091   \n",
       "1        2217  17935944230085744   \n",
       "2       2215S  17899518356507020   \n",
       "3        2214  18014766136389857   \n",
       "4        2203  17924318627206870   \n",
       "\n",
       "                                 comment_description sentiment  \n",
       "0  لخسارة الوزن الزائد والكرش بمدة قياسية مع عدم ...  Negative  \n",
       "1                                                🔥🔥🔥  Positive  \n",
       "2  This is so good😍 would be great it If you add ...  Negative  \n",
       "3                                                  😍  Positive  \n",
       "4       طبق رائع ومميز تبارك الرحمن تسلم ايدك يارب 😍  Positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_train_data=\"../Dataset/train_data.csv\"\n",
    "path_to_test_data=\"../Dataset/test_data.csv\"\n",
    "train_data= pd.read_csv(path_to_train_data)\n",
    "test_data= pd.read_csv(path_to_test_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset caracteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign_id            object\n",
      "comment_id              int64\n",
      "comment_description    object\n",
      "sentiment              object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">comment_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevant</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.803449e+16</td>\n",
       "      <td>2.727242e+13</td>\n",
       "      <td>1.801520e+16</td>\n",
       "      <td>1.802484e+16</td>\n",
       "      <td>1.803449e+16</td>\n",
       "      <td>1.804413e+16</td>\n",
       "      <td>1.805377e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1082.0</td>\n",
       "      <td>1.799547e+16</td>\n",
       "      <td>1.215232e+14</td>\n",
       "      <td>1.784320e+16</td>\n",
       "      <td>1.791969e+16</td>\n",
       "      <td>1.795389e+16</td>\n",
       "      <td>1.802626e+16</td>\n",
       "      <td>1.840129e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>4416.0</td>\n",
       "      <td>1.799213e+16</td>\n",
       "      <td>1.177287e+14</td>\n",
       "      <td>1.784217e+16</td>\n",
       "      <td>1.791955e+16</td>\n",
       "      <td>1.795206e+16</td>\n",
       "      <td>1.801864e+16</td>\n",
       "      <td>1.840678e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           comment_id                                                          \\\n",
       "                count          mean           std           min           25%   \n",
       "sentiment                                                                       \n",
       "Irrelevant        2.0  1.803449e+16  2.727242e+13  1.801520e+16  1.802484e+16   \n",
       "Negative       1082.0  1.799547e+16  1.215232e+14  1.784320e+16  1.791969e+16   \n",
       "Positive       4416.0  1.799213e+16  1.177287e+14  1.784217e+16  1.791955e+16   \n",
       "\n",
       "                                                      \n",
       "                     50%           75%           max  \n",
       "sentiment                                             \n",
       "Irrelevant  1.803449e+16  1.804413e+16  1.805377e+16  \n",
       "Negative    1.795389e+16  1.802626e+16  1.840129e+16  \n",
       "Positive    1.795206e+16  1.801864e+16  1.840678e+16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.dtypes)\n",
    "train_data.groupby('sentiment').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and building Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Bert_encoder (KerasLayer)      [(None, 768),        177853441   ['input_word_ids[0][0]',         \n",
      "                                 (None, None, 768)]               'input_mask[0][0]',             \n",
      "                                                                  'input_type_ids[0][0]']         \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            769         ['Bert_encoder[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 177,854,210\n",
      "Trainable params: 177,854,209\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path= \"./Bert_model/bert_cased\"\n",
    "\n",
    "def define_model(model_path):\n",
    "    # Loading model and preprocessor    \n",
    "    input_word_ids = Input(shape=(None,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(None,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_type_ids = Input(shape=(None,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "    bert_layer = hub.KerasLayer(model_path, trainable=True,name='Bert_encoder')\n",
    "    bert_outputs = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
    "    output_layer = Dense(1, activation='sigmoid',name='classifier')(bert_outputs[0])  # Binary classification, change units for multi-class\n",
    "    model = Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output_layer)\n",
    "    return model\n",
    "bert_classifier=define_model(model_path)\n",
    "bert_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing non arabic and non english comment from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">comment_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>748.0</td>\n",
       "      <td>1.799555e+16</td>\n",
       "      <td>1.207890e+14</td>\n",
       "      <td>1.784369e+16</td>\n",
       "      <td>1.792342e+16</td>\n",
       "      <td>1.795275e+16</td>\n",
       "      <td>1.802685e+16</td>\n",
       "      <td>1.840129e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>3424.0</td>\n",
       "      <td>1.799249e+16</td>\n",
       "      <td>1.171602e+14</td>\n",
       "      <td>1.784217e+16</td>\n",
       "      <td>1.791995e+16</td>\n",
       "      <td>1.795221e+16</td>\n",
       "      <td>1.801843e+16</td>\n",
       "      <td>1.840678e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          comment_id                                                          \\\n",
       "               count          mean           std           min           25%   \n",
       "sentiment                                                                      \n",
       "Negative       748.0  1.799555e+16  1.207890e+14  1.784369e+16  1.792342e+16   \n",
       "Positive      3424.0  1.799249e+16  1.171602e+14  1.784217e+16  1.791995e+16   \n",
       "\n",
       "                                                     \n",
       "                    50%           75%           max  \n",
       "sentiment                                            \n",
       "Negative   1.795275e+16  1.802685e+16  1.840129e+16  \n",
       "Positive   1.795221e+16  1.801843e+16  1.840678e+16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove sentiments with irrelevant class because they are only two\n",
    "irrelevant_indexes=train_data[train_data['sentiment']=='Irrelevant'].index\n",
    "train_data.drop(irrelevant_indexes,inplace=True)\n",
    "\n",
    "# Setting the limit for comments \n",
    "long_indexes= train_data[train_data['comment_description'].str.len()>=100].index\n",
    "train_data.drop(long_indexes,inplace=True)\n",
    "\n",
    "# remove non english and non arabic comments \n",
    "i=0\n",
    "while i <= len(train_data):\n",
    "    try:\n",
    "        lang= detect(train_data.iloc[i,2])\n",
    "        if lang !='ar' and lang !='eng':\n",
    "            train_data.drop(i,inplace=True)\n",
    "            i=i+1\n",
    "        else:\n",
    "            i=i+1\n",
    "            continue\n",
    "    except:\n",
    "        i=i+1\n",
    "        continue\n",
    "train_data.groupby('sentiment').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 748, 1496)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blance data\n",
    "positive_data= train_data[train_data['sentiment']=='Positive'][:748]\n",
    "negative_data= train_data[train_data['sentiment']=='Negative']\n",
    "balanced_train_data=pd.concat([positive_data,negative_data])\n",
    "balanced_train_data=balanced_train_data.sample(frac=1)\n",
    "len(negative_data), len(positive_data),len(balanced_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting comment and sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments=balanced_train_data['comment_description'].astype(str).values\n",
    "#changing sentiment labels from (negativ, positive) to (0,1)\n",
    "train_labels=balanced_train_data['sentiment'].astype(str)\n",
    "train_labels,uniques=pd.factorize(train_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1496, 64), dtype=int32, numpy=\n",
       " array([[   101,  71426, 100745, ...,      0,      0,      0],\n",
       "        [   101,  79660,  16498, ...,      0,      0,      0],\n",
       "        [   101,  15764,    791, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [   101,    776,  11145, ...,      0,      0,      0],\n",
       "        [   101,  60844,  10429, ...,      0,      0,      0],\n",
       "        [   101,    787,  12497, ...,      0,      0,      0]])>,\n",
       " <tf.Tensor: shape=(1496, 64), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " <tf.Tensor: shape=(1496, 64), dtype=int32, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_path=\"./Bert_model/bert_multi_cased_preprocessor\"\n",
    "preprocessor = hub.load(preprocessor_path)\n",
    "\n",
    "# Tokenize batches of both text inputs.\n",
    "text_premises = tf.constant(train_comments)\n",
    "tokenized_premises = preprocessor.tokenize(text_premises)\n",
    "\n",
    "# Pack input sequences for the Transformer encoder.\n",
    "seq_length = 64\n",
    "# convert to word_id and adding padding and mask_id\n",
    "def tokenize_data(tokenized_premises):\n",
    "    with tf.device('/CPU:0'):\n",
    "        encoder_inputs = preprocessor.bert_pack_inputs(\n",
    "            [tokenized_premises],\n",
    "            seq_length=seq_length)  # Optional argument.\n",
    "    return [encoder_inputs['input_word_ids'],encoder_inputs['input_mask'],encoder_inputs['input_type_ids']]\n",
    "tokenizeed_comments = tokenize_data(tokenized_premises)\n",
    "tokenizeed_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate pretrained Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mbert_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnice one\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\KYORAK~1\\AppData\\Local\\Temp\\__autograph_generated_filel2mlbo5j.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>]\n"
     ]
    }
   ],
   "source": [
    "pred = bert_classifier.predict(['nice one'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model compiling and Hyperparameters congiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\kyorakuna\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "opt= tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "bert_classifier.compile(optimizer=opt,loss='binary_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set to use CPU only\n",
    "# model fit on the data\n",
    "epochs=3\n",
    "batch_size = 1\n",
    "\n",
    "bert_classifier.fit(\n",
    "    x={'input_word_ids':tokenizeed_comments[0],'input_mask':tokenizeed_comments[1],'input_type_ids':tokenizeed_comments[2]},\n",
    "    y=train_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier.save('../backend/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
